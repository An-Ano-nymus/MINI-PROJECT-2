{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8292077c",
   "metadata": {},
   "source": [
    "# SEV-CV: Self-Evolutionary Generative Transformers (TensorFlow, Kaggle)\n",
    "\n",
    "This Kaggle notebook trains a minimal SEV-CV model with an evolutionary controller using TFDS data downloaded from a Google Drive folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46681638",
   "metadata": {},
   "source": [
    "### How to run on Kaggle (T4 GPU)\n",
    "1) In Settings: enable GPU (T4) and turn Internet ON.\n",
    "2) Step 1: Run setup and GPU check.\n",
    "3) Step 2: Download TFDS data from your Google Drive folder link (uses gdown) into `/kaggle/working/tfds-cache`.\n",
    "4) Step 3: Confirm TFDS_DIR points to that cache.\n",
    "5) Step 4â€“6: Build models, data loaders, and training utils.\n",
    "6) Step 7: Sanity check.\n",
    "7) Step 8: Train. Set `dataset = 'coco2017'` or `'cifar10'` to use TFDS, or `'folder'` if you downloaded raw images into `DATA_DIR/custom_images`.\n",
    "\n",
    "Notes:\n",
    "- The provided Drive folder should contain TFDS-structured data (e.g., `coco/2017/...`, `cifar10/...`).\n",
    "- For raw images, download a folder and use `dataset='folder'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00561bfe",
   "metadata": {},
   "source": [
    "## Step 1: Setup (TensorFlow + TFDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c857b81",
   "metadata": {},
   "source": [
    "## Step 2: Download TFDS data from Google Drive (Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle-only: download TFDS datasets from shared Google Drive folder\n",
    "# Provided link (must be public/shared):\n",
    "DRIVE_FOLDER_URL = 'https://drive.google.com/drive/folders/1ztC0uxfQLzc627sWihuuzkLo-d5P4kgy'\n",
    "\n",
    "import os, sys, subprocess\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = '/kaggle/working/SEV-CV/datasets'\n",
    "TFDS_DIR = '/kaggle/working/tfds-cache'\n",
    "LOCAL_TFDS_DIR = TFDS_DIR\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TFDS_DIR, exist_ok=True)\n",
    "\n",
    "# Install gdown and download entire folder\n",
    "try:\n",
    "    import gdown  # type: ignore\n",
    "except Exception:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'gdown>=4.7.1'])\n",
    "    import gdown  # type: ignore\n",
    "\n",
    "print('Downloading TFDS folder from Drive into', TFDS_DIR)\n",
    "gdown.download_folder(DRIVE_FOLDER_URL, output=TFDS_DIR, quiet=False, use_cookies=False)\n",
    "\n",
    "# Show top-level TFDS contents\n",
    "print('TFDS_DIR =', TFDS_DIR)\n",
    "for root, dirs, files in os.walk(TFDS_DIR):\n",
    "    print('Sample:', root)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49aee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: TensorFlow + TFDS (Kaggle)\n",
    "import sys, subprocess, pkgutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Enable GPU memory growth to avoid OOM spikes\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print('TF version:', tf.__version__)\n",
    "print('TFDS version:', tfds.__version__)\n",
    "print('GPUs:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick GPU check\n",
    "import tensorflow as tf\n",
    "print('GPUs:', tf.config.list_physical_devices('GPU'))\n",
    "try:\n",
    "    from tensorflow.python.client import device_lib\n",
    "    print('Devices:', [d.name for d in device_lib.list_local_devices()])\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a44d78b",
   "metadata": {},
   "source": [
    "## Step 4: Define models (SEV-G and SEV-D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56351375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models: SEVGenerator and SEVDiscriminator (minimal)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "class MLPBlock(layers.Layer):\n",
    "    def __init__(self, dim, mlp_ratio=4.0, drop=0.0):\n",
    "        super().__init__()\n",
    "        hidden = int(dim * mlp_ratio)\n",
    "        self.fc1 = layers.Dense(hidden)\n",
    "        self.act = layers.Activation(tf.nn.gelu)\n",
    "        self.fc2 = layers.Dense(dim)\n",
    "        self.drop = layers.Dropout(drop)\n",
    "    def call(self, x, training=False):\n",
    "        h = self.fc1(x)\n",
    "        h = self.act(h)\n",
    "        h = self.drop(h, training=training)\n",
    "        h = self.fc2(h)\n",
    "        h = self.drop(h, training=training)\n",
    "        return h\n",
    "\n",
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(self, dim, heads):\n",
    "        super().__init__()\n",
    "        self.attn = layers.MultiHeadAttention(num_heads=heads, key_dim=dim // heads)\n",
    "        self.nq = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.nk = layers.LayerNormalization(epsilon=1e-6)\n",
    "    def call(self, x, training=False):\n",
    "        q = self.nq(x)\n",
    "        k = self.nk(x)\n",
    "        return self.attn(q, k, training=training)\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, dim, heads, mlp_ratio=4.0, drop=0.0):\n",
    "        super().__init__()\n",
    "        self.n1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.attn = WindowAttention(dim, heads)\n",
    "        self.drop = layers.Dropout(drop)\n",
    "        self.n2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.mlp = MLPBlock(dim, mlp_ratio, drop)\n",
    "    def call(self, x, training=False):\n",
    "        h = self.attn(self.n1(x), training=training)\n",
    "        x = x + self.drop(h, training=training)\n",
    "        h = self.mlp(self.n2(x), training=training)\n",
    "        x = x + self.drop(h, training=training)\n",
    "        return x\n",
    "\n",
    "class PatchUpsample(layers.Layer):\n",
    "    def __init__(self, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv2DTranspose(out_ch, 4, 2, padding=\"same\")\n",
    "        self.act = layers.Activation(tf.nn.gelu)\n",
    "    def call(self, x, training=False):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "class SEVGenerator(keras.Model):\n",
    "    def __init__(self, latent_dim=128, base_dim=256, img_size=32, channels=3, depth=4, heads=4):\n",
    "        super().__init__()\n",
    "        if img_size % 4 != 0:\n",
    "            raise ValueError(\"img_size must be divisible by 4\")\n",
    "        start = img_size // 4\n",
    "        self.img_size = img_size\n",
    "        self.fc = layers.Dense(start * start * base_dim)\n",
    "        self.reshape = layers.Reshape((start, start, base_dim))\n",
    "        self.up1 = PatchUpsample(base_dim // 2)\n",
    "        self.up2 = PatchUpsample(base_dim // 4)\n",
    "        self.to_tokens = layers.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, tf.shape(x)[-1]]))\n",
    "        self.blocks = [TransformerBlock(base_dim // 4, heads) for _ in range(depth)]\n",
    "        self.to_feat = layers.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], img_size, img_size, tf.shape(x)[-1]]))\n",
    "        self.out = layers.Conv2D(channels, 1, padding=\"same\", activation=\"tanh\")\n",
    "    def call(self, z, training=False):\n",
    "        h = self.fc(z)\n",
    "        h = self.reshape(h)\n",
    "        h = self.up1(h, training=training)\n",
    "        h = self.up2(h, training=training)\n",
    "        t = self.to_tokens(h)\n",
    "        for b in self.blocks:\n",
    "            t = b(t, training=training)\n",
    "        f = self.to_feat(t)\n",
    "        return self.out(f)\n",
    "\n",
    "class SEVDiscriminator(keras.Model):\n",
    "    def __init__(self, img_size=32, channels=3, base=64, heads=4, depth=2):\n",
    "        super().__init__()\n",
    "        self.stem = keras.Sequential([\n",
    "            layers.Conv2D(base, 4, 2, padding=\"same\"), layers.LeakyReLU(0.2),\n",
    "            layers.Conv2D(base*2, 4, 2, padding=\"same\"), layers.LeakyReLU(0.2),\n",
    "        ])\n",
    "        self.flatten_hw = layers.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, tf.shape(x)[-1]]))\n",
    "        dim = base*2\n",
    "        self.blocks = [TransformerBlock(dim, heads) for _ in range(depth)]\n",
    "        self.pool = layers.GlobalAveragePooling1D()\n",
    "        self.out = layers.Dense(1)\n",
    "    def call(self, x, training=False):\n",
    "        h = self.stem(x, training=training)\n",
    "        t = self.flatten_hw(h)\n",
    "        for b in self.blocks:\n",
    "            t = b(t, training=training)\n",
    "        h = self.pool(t)\n",
    "        return self.out(h)\n",
    "\n",
    "def build_g(latent_dim=128, img=32, ch=3):\n",
    "    return SEVGenerator(latent_dim=latent_dim, img_size=img, channels=ch)\n",
    "\n",
    "def build_d(img=32, ch=3):\n",
    "    return SEVDiscriminator(img_size=img, channels=ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40fad5",
   "metadata": {},
   "source": [
    "## Step 5: Define data loaders (TFDS or image folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config: choose dataset source on Kaggle\n",
    "# Set one of these and run the cell:\n",
    "# - Set SHARED_URL to a Google Drive file (zip/tfrecords) to fetch via gdown\n",
    "# - Or set EXISTING_DATA_PATH to a path already present (e.g., from a Kaggle Dataset)\n",
    "import os\n",
    "SHARED_URL = ''  # e.g., 'https://drive.google.com/uc?id=FILE_ID'\n",
    "EXISTING_DATA_PATH = ''  # e.g., '/kaggle/input/your-dataset'\n",
    "\n",
    "if SHARED_URL:\n",
    "    import gdown\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    out_zip = os.path.join(DATA_DIR, 'dataset.zip')\n",
    "    print('Downloading from Drive via gdown...')\n",
    "    gdown.download(SHARED_URL, out_zip, quiet=False)\n",
    "    try:\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(out_zip, 'r') as zf:\n",
    "            zf.extractall(DATA_DIR)\n",
    "        print('Extracted to', DATA_DIR)\n",
    "    except zipfile.BadZipFile:\n",
    "        print('Downloaded file is not a zip; leaving as-is at', out_zip)\n",
    "elif EXISTING_DATA_PATH and os.path.exists(EXISTING_DATA_PATH):\n",
    "    # If TFDS-like structure exists, we can point TFDS there\n",
    "    print('Using EXISTING_DATA_PATH =', EXISTING_DATA_PATH)\n",
    "else:\n",
    "    print('Using local DATA_DIR =', DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00322a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: CIFAR-10 and COCO2017 (subset)\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def _preprocess(ex, img_size):\n",
    "    x = tf.image.convert_image_dtype(ex['image'], tf.float32)\n",
    "    h = tf.shape(x)[0]\n",
    "    w = tf.shape(x)[1]\n",
    "    side = tf.minimum(h, w)\n",
    "    x = tf.image.resize_with_crop_or_pad(x, side, side)\n",
    "    x = tf.image.resize(x, [img_size, img_size], method='bilinear')\n",
    "    x = x * 2.0 - 1.0\n",
    "    return x\n",
    "\n",
    "def make_cifar10(batch=64, img=32, split='train', data_dir=None,\n",
    "                 shuffle_buf=5000, parallel_calls=2, prefetch=2):\n",
    "    ds = tfds.load('cifar10', split=split, as_supervised=False, shuffle_files=True, data_dir=data_dir)\n",
    "    ds = ds.map(lambda e: _preprocess(e, img), num_parallel_calls=parallel_calls)\n",
    "    ds = ds.shuffle(shuffle_buf).batch(batch, drop_remainder=True)\n",
    "    return ds.prefetch(prefetch)\n",
    "\n",
    "def make_coco2017(batch=32, img=128, split='train[0%:20%]', data_dir=None,\n",
    "                  shuffle_buf=2000, parallel_calls=2, prefetch=2):\n",
    "    ds = tfds.load('coco/2017', split=split, as_supervised=False, shuffle_files=True, data_dir=data_dir)\n",
    "    ds = ds.map(lambda e: _preprocess(e, img), num_parallel_calls=parallel_calls)\n",
    "    ds = ds.shuffle(shuffle_buf).batch(batch, drop_remainder=True)\n",
    "    return ds.prefetch(prefetch)\n",
    "\n",
    "# Optional: Load from a folder of images in Drive\n",
    "def _load_image_file(path, img_size):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    h = tf.shape(img)[0]\n",
    "    w = tf.shape(img)[1]\n",
    "    side = tf.minimum(h, w)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, side, side)\n",
    "    img = tf.image.resize(img, [img_size, img_size], method='bilinear')\n",
    "    img = img * 2.0 - 1.0\n",
    "    return img\n",
    "\n",
    "def make_folder_dataset(folder, batch=32, img=128, shuffle_buf=2000, parallel_calls=2, prefetch=2):\n",
    "    files = tf.data.Dataset.list_files(os.path.join(folder, '**', '*.*'), shuffle=True)\n",
    "    ds = files.map(lambda p: _load_image_file(p, img), num_parallel_calls=parallel_calls)\n",
    "    ds = ds.shuffle(shuffle_buf).batch(batch, drop_remainder=True)\n",
    "    return ds.prefetch(prefetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution controller + training utils\n",
    "import dataclasses, random\n",
    "import tensorflow as tf\n",
    "from typing import List\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Individual:\n",
    "    lr: float\n",
    "    heads: int\n",
    "    depth: int\n",
    "    score: float = 0.0\n",
    "\n",
    "class EvolutionController:\n",
    "    def __init__(self, population=4, seed=0):\n",
    "        random.seed(seed)\n",
    "        self.population: List[Individual] = []\n",
    "        for _ in range(population):\n",
    "            self.population.append(Individual(lr=1e-4*10**random.uniform(-0.5,0.5), heads=random.choice([2,4,6]), depth=random.choice([2,4,6])))\n",
    "    def mutate(self, ind: Individual) -> Individual:\n",
    "        return Individual(\n",
    "            lr=max(1e-5, min(5e-4, ind.lr * (1.0 + random.uniform(-0.3,0.3)))),\n",
    "            heads=max(2, min(8, ind.heads + random.choice([-2,0,2]))),\n",
    "            depth=max(2, min(8, ind.depth + random.choice([-2,0,2]))),\n",
    "        )\n",
    "    def select(self, k=2):\n",
    "        self.population.sort(key=lambda i: i.score, reverse=True)\n",
    "        self.population = self.population[:k] + [self.mutate(self.population[i%k]) for i in range(k, len(self.population))]\n",
    "\n",
    "# Losses\n",
    "@tf.function\n",
    "def d_loss_fn(real_logits, fake_logits):\n",
    "    return tf.reduce_mean(tf.nn.relu(1.0 - real_logits)) + tf.reduce_mean(tf.nn.relu(1.0 + fake_logits))\n",
    "\n",
    "@tf.function\n",
    "def g_loss_fn(fake_logits):\n",
    "    return -tf.reduce_mean(fake_logits)\n",
    "\n",
    "class HingeGAN:\n",
    "    def __init__(self, img=32, z=128, heads=4, depth=4, lr=2e-4):\n",
    "        self.G = SEVGenerator(latent_dim=z, img_size=img, channels=3, depth=depth, heads=heads)\n",
    "        self.D = SEVDiscriminator(img_size=img, channels=3, heads=heads, depth=2)\n",
    "        self.opt_g = keras.optimizers.Adam(lr, beta_1=0.0, beta_2=0.99)\n",
    "        self.opt_d = keras.optimizers.Adam(lr, beta_1=0.0, beta_2=0.99)\n",
    "        self.z = z\n",
    "    @tf.function\n",
    "    def step(self, real):\n",
    "        b = tf.shape(real)[0]\n",
    "        noise = tf.random.normal([b, self.z])\n",
    "        with tf.GradientTape() as td:\n",
    "            fake = self.G(noise, training=True)\n",
    "            r = self.D(real, training=True)\n",
    "            f = self.D(fake, training=True)\n",
    "            dl = d_loss_fn(r, f)\n",
    "        dvars = self.D.trainable_variables\n",
    "        dgrads = td.gradient(dl, dvars)\n",
    "        self.opt_d.apply_gradients(zip(dgrads, dvars))\n",
    "\n",
    "        noise = tf.random.normal([b, self.z])\n",
    "        with tf.GradientTape() as tg:\n",
    "            fake = self.G(noise, training=True)\n",
    "            f = self.D(fake, training=True)\n",
    "            gl = g_loss_fn(f)\n",
    "        gvars = self.G.trainable_variables\n",
    "        ggrads = tg.gradient(gl, gvars)\n",
    "        self.opt_g.apply_gradients(zip(ggrads, gvars))\n",
    "        return dl, gl\n",
    "\n",
    "    def sample_fitness(self, n=4):\n",
    "        z = tf.random.normal([n, self.z])\n",
    "        imgs = self.G(z, training=False)\n",
    "        # simple proxy: encourage variance\n",
    "        return float(tf.math.reduce_std(imgs).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c1113",
   "metadata": {},
   "source": [
    "## Step 6: Evolution + training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1864ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train: Kaggle-only evolution-guided loop using TFDS from downloaded Drive cache\n",
    "import time, os, tensorflow as tf\n",
    "\n",
    "# Options: 'cifar10', 'coco2017', or 'folder'\n",
    "dataset = 'coco2017'  # default\n",
    "low_mem = True\n",
    "\n",
    "# Defaults\n",
    "img = 128 if dataset=='coco2017' else 32\n",
    "batch = 32 if dataset=='coco2017' else 64\n",
    "steps = 200\n",
    "\n",
    "# Low-memory overrides\n",
    "if low_mem:\n",
    "    if dataset=='coco2017':\n",
    "        img = 64\n",
    "        batch = 8\n",
    "    else:\n",
    "        batch = 32\n",
    "    steps = 100\n",
    "\n",
    "# Source dirs (set by Step 2)\n",
    "DATA_DIR = '/kaggle/working/SEV-CV/datasets'\n",
    "TFDS_DIR = '/kaggle/working/tfds-cache'\n",
    "LOCAL_TFDS_DIR = TFDS_DIR\n",
    "\n",
    "# Folder dataset path (if using raw images)\n",
    "custom_folder = os.path.join(DATA_DIR, 'custom_images')\n",
    "os.makedirs(custom_folder, exist_ok=True)\n",
    "\n",
    "# Data constructors with conservative buffers\n",
    "make_kwargs = dict(shuffle_buf=1000, parallel_calls=1, prefetch=1) if low_mem else {}\n",
    "\n",
    "def make_ds():\n",
    "    if dataset=='cifar10':\n",
    "        return make_cifar10(batch=batch, img=img, split='train', data_dir=TFDS_DIR, **make_kwargs)\n",
    "    elif dataset=='coco2017':\n",
    "        split = 'train[0%:5%]' if low_mem else 'train[0%:10%]'\n",
    "        return make_coco2017(batch=batch, img=img, split=split, data_dir=TFDS_DIR, **make_kwargs)\n",
    "    else:\n",
    "        return make_folder_dataset(custom_folder, batch=batch, img=img, **make_kwargs)\n",
    "\n",
    "# Build initial models\n",
    "ds = make_ds()\n",
    "it = iter(ds)\n",
    "evo = EvolutionController(population=2 if low_mem else 4, seed=42)\n",
    "\n",
    "def build_g_cfg(heads, depth):\n",
    "    if low_mem:\n",
    "        return SEVGenerator(latent_dim=96, img_size=img, channels=3, depth=max(2, depth//2), heads=max(2, heads//2), base_dim=192)\n",
    "    return SEVGenerator(latent_dim=128, img_size=img, channels=3, depth=depth, heads=heads)\n",
    "\n",
    "def build_d_cfg(heads):\n",
    "    if low_mem:\n",
    "        return SEVDiscriminator(img_size=img, channels=3, heads=max(2, heads//2), depth=1, base=48)\n",
    "    return SEVDiscriminator(img_size=img, channels=3, heads=heads, depth=2)\n",
    "\n",
    "models = []\n",
    "for ind in evo.population:\n",
    "    gan = HingeGAN(img=img, z=96 if low_mem else 128, heads=ind.heads, depth=ind.depth, lr=ind.lr)\n",
    "    gan.G = build_g_cfg(ind.heads, ind.depth)\n",
    "    gan.D = build_d_cfg(ind.heads)\n",
    "    models.append(gan)\n",
    "\n",
    "for step in range(1, steps+1):\n",
    "    real = next(it)\n",
    "    for gan in models:\n",
    "        dl, gl = gan.step(real)\n",
    "    if step % 25 == 0:\n",
    "        for i, (gan, ind) in enumerate(zip(models, evo.population)):\n",
    "            ind.score = gan.sample_fitness(n=2 if low_mem else 4)\n",
    "        evo.select(k=1 if low_mem else 2)\n",
    "        models = []\n",
    "        for ind in evo.population:\n",
    "            new_gan = HingeGAN(img=img, z=96 if low_mem else 128, heads=ind.heads, depth=ind.depth, lr=ind.lr)\n",
    "            new_gan.G = build_g_cfg(ind.heads, ind.depth)\n",
    "            new_gan.D = build_d_cfg(ind.heads)\n",
    "            models.append(new_gan)\n",
    "        print(f\"[step {step}] evolved heads/depth/lr:\", [(ind.heads, ind.depth, round(ind.lr,6)) for ind in evo.population])\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34802a79",
   "metadata": {},
   "source": [
    "## Step 8: Train\n",
    "Pick the dataset, adjust img/batch/steps, and run the loop. Models evolve every 25 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b60476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: forward generator at chosen resolution\n",
    "img_test = 128\n",
    "G_test = SEVGenerator(latent_dim=128, img_size=img_test, channels=3, depth=2, heads=4)\n",
    "y = G_test(tf.random.normal([2,128]), training=False)\n",
    "print('gen out shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8647a",
   "metadata": {},
   "source": [
    "## Step 7: Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm TFDS_DIR for Kaggle-only workflow (no download here)\n",
    "import os\n",
    "TFDS_DIR = '/kaggle/working/tfds-cache'\n",
    "LOCAL_TFDS_DIR = TFDS_DIR\n",
    "print('TFDS dir:', TFDS_DIR)\n",
    "print('Contents:')\n",
    "for p in os.listdir(TFDS_DIR):\n",
    "    print('-', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0c386",
   "metadata": {},
   "source": [
    "## Step 3: Confirm TFDS_DIR (Kaggle)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
