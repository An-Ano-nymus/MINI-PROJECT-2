{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8292077c",
   "metadata": {},
   "source": [
    "# SEV-CV: Self-Evolutionary Generative Transformers (TensorFlow, Colab)\n",
    "\n",
    "\n",
    "This Colab trains a minimal SEV-CV model with an evolutionary controller on CIFAR-10 or COCO 2017 (subset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46681638",
   "metadata": {},
   "source": [
    "### How to run in Colab (order)\n",
    "1) Setup: verify TensorFlow/TFDS versions.\n",
    "2) Mount Google Drive and set DATA_DIR.\n",
    "3) Prepare datasets into Drive (TFDS or unzip your own images).\n",
    "4) Define models (Generator/Discriminator).\n",
    "5) Define data loaders (CIFAR‑10, COCO‑2017, or a Drive folder of images).\n",
    "6) Define evolution + training utilities.\n",
    "7) Sanity check: quick forward pass to confirm shapes.\n",
    "8) Train: pick dataset = 'cifar10' | 'coco2017' | 'folder', adjust img, batch, steps; run training.\n",
    "\n",
    "Tips:\n",
    "- COCO uses a subset split by default for speed; expand it if you have space/time.\n",
    "- All datasets are cached under `/content/drive/MyDrive/SEV-CV/datasets`. Change this if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49aee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: TensorFlow + TFDS (Colab-friendly)\n",
    "import sys, subprocess, pkgutil\n",
    "\n",
    "# Optional pin for Colab stability; comment out if you want runtime default\n",
    "# subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'tensorflow>=2.12,<2.17', 'tensorflow-datasets>=4.9'])\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print('TF version:', tf.__version__)\n",
    "print('TFDS version:', tfds.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b389f",
   "metadata": {},
   "source": [
    "## Step 1: Setup (TensorFlow + TFDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a44d78b",
   "metadata": {},
   "source": [
    "## Step 4: Define models (SEV-G and SEV-D)\n",
    "The generator supports dynamic output sizes; ensure img_size is divisible by 4 (e.g., 32 or 128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56351375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models: SEVGenerator and SEVDiscriminator (minimal)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "class MLPBlock(layers.Layer):\n",
    "    def __init__(self, dim, mlp_ratio=4.0, drop=0.0):\n",
    "        super().__init__()\n",
    "        hidden = int(dim * mlp_ratio)\n",
    "        self.fc1 = layers.Dense(hidden)\n",
    "        self.act = layers.Activation(tf.nn.gelu)\n",
    "        self.fc2 = layers.Dense(dim)\n",
    "        self.drop = layers.Dropout(drop)\n",
    "    def call(self, x, training=False):\n",
    "        h = self.fc1(x)\n",
    "        h = self.act(h)\n",
    "        h = self.drop(h, training=training)\n",
    "        h = self.fc2(h)\n",
    "        h = self.drop(h, training=training)\n",
    "        return h\n",
    "\n",
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(self, dim, heads):\n",
    "        super().__init__()\n",
    "        self.attn = layers.MultiHeadAttention(num_heads=heads, key_dim=dim // heads)\n",
    "        self.nq = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.nk = layers.LayerNormalization(epsilon=1e-6)\n",
    "    def call(self, x, training=False):\n",
    "        q = self.nq(x)\n",
    "        k = self.nk(x)\n",
    "        return self.attn(q, k, training=training)\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, dim, heads, mlp_ratio=4.0, drop=0.0):\n",
    "        super().__init__()\n",
    "        self.n1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.attn = WindowAttention(dim, heads)\n",
    "        self.drop = layers.Dropout(drop)\n",
    "        self.n2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.mlp = MLPBlock(dim, mlp_ratio, drop)\n",
    "    def call(self, x, training=False):\n",
    "        h = self.attn(self.n1(x), training=training)\n",
    "        x = x + self.drop(h, training=training)\n",
    "        h = self.mlp(self.n2(x), training=training)\n",
    "        x = x + self.drop(h, training=training)\n",
    "        return x\n",
    "\n",
    "class PatchUpsample(layers.Layer):\n",
    "    def __init__(self, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv2DTranspose(out_ch, 4, 2, padding=\"same\")\n",
    "        self.act = layers.Activation(tf.nn.gelu)\n",
    "    def call(self, x, training=False):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "class SEVGenerator(keras.Model):\n",
    "    def __init__(self, latent_dim=128, base_dim=256, img_size=32, channels=3, depth=4, heads=4):\n",
    "        super().__init__()\n",
    "        if img_size % 4 != 0:\n",
    "            raise ValueError(\"img_size must be divisible by 4\")\n",
    "        start = img_size // 4\n",
    "        self.img_size = img_size\n",
    "        self.fc = layers.Dense(start * start * base_dim)\n",
    "        self.reshape = layers.Reshape((start, start, base_dim))\n",
    "        self.up1 = PatchUpsample(base_dim // 2)\n",
    "        self.up2 = PatchUpsample(base_dim // 4)\n",
    "        self.to_tokens = layers.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, tf.shape(x)[-1]]))\n",
    "        self.blocks = [TransformerBlock(base_dim // 4, heads) for _ in range(depth)]\n",
    "        self.to_feat = layers.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], img_size, img_size, tf.shape(x)[-1]]))\n",
    "        self.out = layers.Conv2D(channels, 1, padding=\"same\", activation=\"tanh\")\n",
    "    def call(self, z, training=False):\n",
    "        h = self.fc(z)\n",
    "        h = self.reshape(h)\n",
    "        h = self.up1(h, training=training)\n",
    "        h = self.up2(h, training=training)\n",
    "        t = self.to_tokens(h)\n",
    "        for b in self.blocks:\n",
    "            t = b(t, training=training)\n",
    "        f = self.to_feat(t)\n",
    "        return self.out(f)\n",
    "\n",
    "class SEVDiscriminator(keras.Model):\n",
    "    def __init__(self, img_size=32, channels=3, base=64, heads=4, depth=2):\n",
    "        super().__init__()\n",
    "        self.stem = keras.Sequential([\n",
    "            layers.Conv2D(base, 4, 2, padding=\"same\"), layers.LeakyReLU(0.2),\n",
    "            layers.Conv2D(base*2, 4, 2, padding=\"same\"), layers.LeakyReLU(0.2),\n",
    "        ])\n",
    "        self.flatten_hw = layers.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, tf.shape(x)[-1]]))\n",
    "        dim = base*2\n",
    "        self.blocks = [TransformerBlock(dim, heads) for _ in range(depth)]\n",
    "        self.pool = layers.GlobalAveragePooling1D()\n",
    "        self.out = layers.Dense(1)\n",
    "    def call(self, x, training=False):\n",
    "        h = self.stem(x, training=training)\n",
    "        t = self.flatten_hw(h)\n",
    "        for b in self.blocks:\n",
    "            t = b(t, training=training)\n",
    "        h = self.pool(t)\n",
    "        return self.out(h)\n",
    "\n",
    "def build_g(latent_dim=128, img=32, ch=3):\n",
    "    return SEVGenerator(latent_dim=latent_dim, img_size=img, channels=ch)\n",
    "\n",
    "def build_d(img=32, ch=3):\n",
    "    return SEVDiscriminator(img_size=img, channels=ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40fad5",
   "metadata": {},
   "source": [
    "## Step 5: Define data loaders (TFDS or image folder)\n",
    "These functions read from Drive-backed TFDS or a folder of images under DATA_DIR/custom_images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00322a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: CIFAR-10 and COCO2017 (subset)\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def _preprocess(ex, img_size):\n",
    "    x = tf.image.convert_image_dtype(ex['image'], tf.float32)\n",
    "    h = tf.shape(x)[0]\n",
    "    w = tf.shape(x)[1]\n",
    "    side = tf.minimum(h, w)\n",
    "    x = tf.image.resize_with_crop_or_pad(x, side, side)\n",
    "    x = tf.image.resize(x, [img_size, img_size], method='bilinear')\n",
    "    x = x * 2.0 - 1.0\n",
    "    return x\n",
    "\n",
    "def make_cifar10(batch=64, img=32, split='train', data_dir=None,\n",
    "                 shuffle_buf=5000, parallel_calls=2, prefetch=2):\n",
    "    ds = tfds.load('cifar10', split=split, as_supervised=False, shuffle_files=True, data_dir=data_dir)\n",
    "    ds = ds.map(lambda e: _preprocess(e, img), num_parallel_calls=parallel_calls)\n",
    "    ds = ds.shuffle(shuffle_buf).batch(batch, drop_remainder=True)\n",
    "    return ds.prefetch(prefetch)\n",
    "\n",
    "def make_coco2017(batch=32, img=128, split='train[0%:20%]', data_dir=None,\n",
    "                  shuffle_buf=2000, parallel_calls=2, prefetch=2):\n",
    "    ds = tfds.load('coco/2017', split=split, as_supervised=False, shuffle_files=True, data_dir=data_dir)\n",
    "    ds = ds.map(lambda e: _preprocess(e, img), num_parallel_calls=parallel_calls)\n",
    "    ds = ds.shuffle(shuffle_buf).batch(batch, drop_remainder=True)\n",
    "    return ds.prefetch(prefetch)\n",
    "\n",
    "# Optional: Load from a folder of images in Drive\n",
    "def _load_image_file(path, img_size):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    h = tf.shape(img)[0]\n",
    "    w = tf.shape(img)[1]\n",
    "    side = tf.minimum(h, w)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, side, side)\n",
    "    img = tf.image.resize(img, [img_size, img_size], method='bilinear')\n",
    "    img = img * 2.0 - 1.0\n",
    "    return img\n",
    "\n",
    "def make_folder_dataset(folder, batch=32, img=128, shuffle_buf=2000, parallel_calls=2, prefetch=2):\n",
    "    files = tf.data.Dataset.list_files(os.path.join(folder, '**', '*.*'), shuffle=True)\n",
    "    ds = files.map(lambda p: _load_image_file(p, img), num_parallel_calls=parallel_calls)\n",
    "    ds = ds.shuffle(shuffle_buf).batch(batch, drop_remainder=True)\n",
    "    return ds.prefetch(prefetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution controller + training utils\n",
    "import dataclasses, random\n",
    "import tensorflow as tf\n",
    "from typing import List\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Individual:\n",
    "    lr: float\n",
    "    heads: int\n",
    "    depth: int\n",
    "    score: float = 0.0\n",
    "\n",
    "class EvolutionController:\n",
    "    def __init__(self, population=4, seed=0):\n",
    "        random.seed(seed)\n",
    "        self.population: List[Individual] = []\n",
    "        for _ in range(population):\n",
    "            self.population.append(Individual(lr=1e-4*10**random.uniform(-0.5,0.5), heads=random.choice([2,4,6]), depth=random.choice([2,4,6])))\n",
    "    def mutate(self, ind: Individual) -> Individual:\n",
    "        return Individual(\n",
    "            lr=max(1e-5, min(5e-4, ind.lr * (1.0 + random.uniform(-0.3,0.3)))),\n",
    "            heads=max(2, min(8, ind.heads + random.choice([-2,0,2]))),\n",
    "            depth=max(2, min(8, ind.depth + random.choice([-2,0,2]))),\n",
    "        )\n",
    "    def select(self, k=2):\n",
    "        self.population.sort(key=lambda i: i.score, reverse=True)\n",
    "        self.population = self.population[:k] + [self.mutate(self.population[i%k]) for i in range(k, len(self.population))]\n",
    "\n",
    "# Losses\n",
    "@tf.function\n",
    "def d_loss_fn(real_logits, fake_logits):\n",
    "    return tf.reduce_mean(tf.nn.relu(1.0 - real_logits)) + tf.reduce_mean(tf.nn.relu(1.0 + fake_logits))\n",
    "\n",
    "@tf.function\n",
    "def g_loss_fn(fake_logits):\n",
    "    return -tf.reduce_mean(fake_logits)\n",
    "\n",
    "class HingeGAN:\n",
    "    def __init__(self, img=32, z=128, heads=4, depth=4, lr=2e-4):\n",
    "        self.G = SEVGenerator(latent_dim=z, img_size=img, channels=3, depth=depth, heads=heads)\n",
    "        self.D = SEVDiscriminator(img_size=img, channels=3, heads=heads, depth=2)\n",
    "        self.opt_g = keras.optimizers.Adam(lr, beta_1=0.0, beta_2=0.99)\n",
    "        self.opt_d = keras.optimizers.Adam(lr, beta_1=0.0, beta_2=0.99)\n",
    "        self.z = z\n",
    "    @tf.function\n",
    "    def step(self, real):\n",
    "        b = tf.shape(real)[0]\n",
    "        noise = tf.random.normal([b, self.z])\n",
    "        with tf.GradientTape() as td:\n",
    "            fake = self.G(noise, training=True)\n",
    "            r = self.D(real, training=True)\n",
    "            f = self.D(fake, training=True)\n",
    "            dl = d_loss_fn(r, f)\n",
    "        dvars = self.D.trainable_variables\n",
    "        dgrads = td.gradient(dl, dvars)\n",
    "        self.opt_d.apply_gradients(zip(dgrads, dvars))\n",
    "\n",
    "        noise = tf.random.normal([b, self.z])\n",
    "        with tf.GradientTape() as tg:\n",
    "            fake = self.G(noise, training=True)\n",
    "            f = self.D(fake, training=True)\n",
    "            gl = g_loss_fn(f)\n",
    "        gvars = self.G.trainable_variables\n",
    "        ggrads = tg.gradient(gl, gvars)\n",
    "        self.opt_g.apply_gradients(zip(ggrads, gvars))\n",
    "        return dl, gl\n",
    "\n",
    "    def sample_fitness(self, n=4):\n",
    "        z = tf.random.normal([n, self.z])\n",
    "        imgs = self.G(z, training=False)\n",
    "        # simple proxy: encourage variance\n",
    "        return float(tf.math.reduce_std(imgs).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c1113",
   "metadata": {},
   "source": [
    "## Step 6: Evolution + training utilities\n",
    "Implements Hinge-GAN losses and a lightweight evolutionary controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1864ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train: choose dataset and run a short evolution-guided loop\n",
    "import time, os, tensorflow as tf\n",
    "\n",
    "# Options: 'cifar10', 'coco2017', or 'folder'\n",
    "dataset = 'cifar10'  # change to 'coco2017' or 'folder'\n",
    "low_mem = True  # set True to avoid RAM crashes on Colab\n",
    "\n",
    "# Defaults\n",
    "img = 32 if dataset=='cifar10' else 128\n",
    "batch = 64 if dataset=='cifar10' else 32\n",
    "steps = 200\n",
    "\n",
    "# Low-memory overrides\n",
    "if low_mem:\n",
    "    if dataset=='coco2017':\n",
    "        img = 64  # downscale to cut memory\n",
    "        batch = 8  # smaller batch\n",
    "    else:\n",
    "        batch = 32\n",
    "    steps = 100\n",
    "\n",
    "# Point TFDS to Google Drive, else local fallback\n",
    "TFDS_DIR = os.path.join(DATA_DIR, 'tfds') if 'DATA_DIR' in globals() else None\n",
    "LOCAL_TFDS_DIR = globals().get('LOCAL_TFDS_DIR', None)\n",
    "\n",
    "# Data constructors with conservative buffers\n",
    "make_kwargs = dict(shuffle_buf=1000, parallel_calls=1, prefetch=1) if low_mem else {}\n",
    "\n",
    "def make_ds_with_fallback():\n",
    "    try:\n",
    "        if dataset=='cifar10':\n",
    "            return make_cifar10(batch=batch, img=img, split='train', data_dir=TFDS_DIR, **make_kwargs)\n",
    "        elif dataset=='coco2017':\n",
    "            split = 'train[0%:5%]' if low_mem else 'train[0%:10%]'\n",
    "            return make_coco2017(batch=batch, img=img, split=split, data_dir=TFDS_DIR, **make_kwargs)\n",
    "        else:\n",
    "            custom_folder = os.path.join(DATA_DIR, 'custom_images')\n",
    "            os.makedirs(custom_folder, exist_ok=True)\n",
    "            return make_folder_dataset(custom_folder, batch=batch, img=img, **make_kwargs)\n",
    "    except Exception as e:\n",
    "        print('Drive-backed TFDS failed, falling back to local cache. Error:', e)\n",
    "        if dataset=='cifar10':\n",
    "            return make_cifar10(batch=batch, img=img, split='train', data_dir=LOCAL_TFDS_DIR, **make_kwargs)\n",
    "        elif dataset=='coco2017':\n",
    "            split = 'train[0%:5%]' if low_mem else 'train[0%:10%]'\n",
    "            return make_coco2017(batch=batch, img=img, split=split, data_dir=LOCAL_TFDS_DIR, **make_kwargs)\n",
    "        else:\n",
    "            return make_folder_dataset(custom_folder, batch=batch, img=img, **make_kwargs)\n",
    "\n",
    "ds = make_ds_with_fallback()\n",
    "it = iter(ds)\n",
    "evo = EvolutionController(population=2 if low_mem else 4, seed=42)\n",
    "\n",
    "# Smaller models for low_mem\n",
    "def build_g_cfg(heads, depth):\n",
    "    if low_mem:\n",
    "        return SEVGenerator(latent_dim=96, img_size=img, channels=3, depth=max(2, depth//2), heads=max(2, heads//2), base_dim=192)\n",
    "    return SEVGenerator(latent_dim=128, img_size=img, channels=3, depth=depth, heads=heads)\n",
    "\n",
    "def build_d_cfg(heads):\n",
    "    if low_mem:\n",
    "        return SEVDiscriminator(img_size=img, channels=3, heads=max(2, heads//2), depth=1, base=48)\n",
    "    return SEVDiscriminator(img_size=img, channels=3, heads=heads, depth=2)\n",
    "\n",
    "models = []\n",
    "for ind in evo.population:\n",
    "    gan = HingeGAN(img=img, z=96 if low_mem else 128, heads=ind.heads, depth=ind.depth, lr=ind.lr)\n",
    "    # Swap in lighter nets\n",
    "    gan.G = build_g_cfg(ind.heads, ind.depth)\n",
    "    gan.D = build_d_cfg(ind.heads)\n",
    "    models.append(gan)\n",
    "\n",
    "for step in range(1, steps+1):\n",
    "    try:\n",
    "        real = next(it)\n",
    "    except Exception as e:\n",
    "        print('Iterator failed, recreating dataset/iterator. Error:', e)\n",
    "        ds = make_ds_with_fallback()\n",
    "        it = iter(ds)\n",
    "        real = next(it)\n",
    "    for gan in models:\n",
    "        dl, gl = gan.step(real)\n",
    "    if step % 25 == 0:\n",
    "        for i, (gan, ind) in enumerate(zip(models, evo.population)):\n",
    "            ind.score = gan.sample_fitness(n=2 if low_mem else 4)\n",
    "        evo.select(k=1 if low_mem else 2)\n",
    "        models = []\n",
    "        for ind in evo.population:\n",
    "            new_gan = HingeGAN(img=img, z=96 if low_mem else 128, heads=ind.heads, depth=ind.depth, lr=ind.lr)\n",
    "            new_gan.G = build_g_cfg(ind.heads, ind.depth)\n",
    "            new_gan.D = build_d_cfg(ind.heads)\n",
    "            models.append(new_gan)\n",
    "        print(f\"[step {step}] evolved heads/depth/lr:\", [(ind.heads, ind.depth, round(ind.lr,6)) for ind in evo.population])\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34802a79",
   "metadata": {},
   "source": [
    "## Step 8: Train\n",
    "Pick the dataset, adjust img/batch/steps, and run the loop. Models evolve every 25 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b60476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: forward generator at chosen resolution\n",
    "img_test = 128\n",
    "G_test = SEVGenerator(latent_dim=128, img_size=img_test, channels=3, depth=2, heads=4)\n",
    "y = G_test(tf.random.normal([2,128]), training=False)\n",
    "print('gen out shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8647a",
   "metadata": {},
   "source": [
    "## Step 7: Sanity check\n",
    "Forward the generator once at your desired resolution to confirm shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec1060",
   "metadata": {},
   "source": [
    "## Mount Google Drive and set dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac194b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and set dataset folder\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "# Customize the folder name if you like\n",
    "DATA_DIR = '/content/drive/MyDrive/SEV-CV/datasets'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print('DATA_DIR =', DATA_DIR)\n",
    "print('Free space (approx):')\n",
    "!df -h /content/drive | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ee62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force remount Drive, then prefer local cache fallback if instability persists\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.flush_and_unmount()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from google.colab import drive as _drive\n",
    "_drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Local fallback TFDS dir (fast, avoids Drive disconnects). You can copy prepared datasets here if needed.\n",
    "LOCAL_TFDS_DIR = '/content/tfds-cache'\n",
    "import os\n",
    "os.makedirs(LOCAL_TFDS_DIR, exist_ok=True)\n",
    "print('LOCAL_TFDS_DIR =', LOCAL_TFDS_DIR)\n",
    "\n",
    "# Optional: quick check of a few TFRecord shards (skip if not using COCO)\n",
    "import glob\n",
    "coco_glob = '/content/drive/MyDrive/SEV-CV/datasets/tfds/coco/2017/1.1.0/*.tfrecord*'\n",
    "print('Found COCO shards on Drive:', len(glob.glob(coco_glob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a69f3b",
   "metadata": {},
   "source": [
    "### Troubleshooting: Drive disconnects\n",
    "If you see \"Transport endpoint is not connected\", force-remount Drive and retry. Then prefer a local runtime cache (next cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ce7d0",
   "metadata": {},
   "source": [
    "## Step 2: Mount Google Drive and set DATA_DIR\n",
    "This stores datasets/checkpoints persistently under MyDrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Use TFDS to download directly into Drive (recommended)\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "tfds_dir = os.path.join(DATA_DIR, 'tfds')\n",
    "os.makedirs(tfds_dir, exist_ok=True)\n",
    "print('TFDS dir:', tfds_dir)\n",
    "\n",
    "# Example: download CIFAR-10 and COCO 2017 subsets\n",
    "_ = tfds.load('cifar10', data_dir=tfds_dir, split='train', with_info=False)\n",
    "_ = tfds.load('coco/2017', data_dir=tfds_dir, split='train[0%:10%]', with_info=False)\n",
    "print('TFDS prepared under', tfds_dir)\n",
    "\n",
    "# Option B: If you already have a zip/tar on Drive, unzip into DATA_DIR\n",
    "# import zipfile\n",
    "# zip_path = '/content/drive/MyDrive/path/to/your_dataset.zip'\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "#     zf.extractall(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0c386",
   "metadata": {},
   "source": [
    "## Step 3: Prepare datasets into Drive\n",
    "Recommended: TFDS caches under DATA_DIR/tfds. You can also unzip your own images to DATA_DIR/custom_images."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
